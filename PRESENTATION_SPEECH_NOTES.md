# Notes de Discours Oral - Pr√©sentation Architecture S√©curit√© CA-A2A

**Version :** 5.1  
**Bas√© sur :** PRESENTATION_ARCHITECTURE_SECURITE.md  
**Usage :** Notes compl√©mentaires en langage naturel pour le pr√©sentateur

---

## üìå Instructions d'Utilisation

Ce document contient des **notes de discours oral** d√©taill√©es pour accompagner chaque slide de la pr√©sentation `PRESENTATION_ARCHITECTURE_SECURITE.md`. 

**Format :**
- üí¨ **DISCOURS ORAL** : Ce que vous dites mot √† mot
- üîß **REMARQUES TECHNIQUES** : D√©tails techniques suppl√©mentaires si questions
- üí° **CONSEILS** : Astuces pour la pr√©sentation

**Structure :** Suit exactement l'ordre des slides (1-34)

---

## SLIDE 1 - Titre & Ouverture

**üí¨ DISCOURS ORAL :**

"Bonjour √† tous et merci d'√™tre pr√©sents aujourd'hui. Je m'appelle [Votre Nom] et je vais vous pr√©senter l'architecture de s√©curit√© du syst√®me CA-A2A dans sa version 5.1.

Alors, pour commencer, qu'est-ce que CA-A2A ? C'est un syst√®me multi-agents d√©ploy√© sur AWS ECS Fargate qui traite des documents sensibles. Et quand je dis 'multi-agents', je parle de 5 agents sp√©cialis√©s qui communiquent entre eux : un orchestrateur, un extracteur, un validateur, un archiviste, et un serveur MCP qui centralise l'acc√®s aux ressources.

Ce qui rend ce syst√®me particuli√®rement int√©ressant d'un point de vue s√©curit√©, c'est qu'il impl√©mente une approche defense-in-depth avec 9 couches de s√©curit√© **ind√©pendantes**. Et j'insiste sur le mot ind√©pendantes : si une couche √©choue, les 8 autres continuent de prot√©ger le syst√®me. Il n'y a pas de single point of failure.

Le syst√®me est actuellement en production dans la r√©gion AWS eu-west-3, c'est-√†-dire Paris. Nous avons choisi cette r√©gion pour des raisons de conformit√© RGPD et de latence pour nos utilisateurs europ√©ens.

Et justement, en parlant de conformit√©, ce syst√®me a √©t√© con√ßu d√®s le d√©part pour respecter les standards ISO 27001 et SOC 2. Ce n'est pas un ajout apr√®s coup, c'est vraiment dans l'ADN de l'architecture."

**üîß REMARQUES TECHNIQUES (si questions) :**
- **Pourquoi Fargate ?** ‚Üí Serverless, pas de gestion de serveurs EC2, patching automatique
- **Multi-AZ ?** ‚Üí Oui, d√©ploy√© sur eu-west-3a et eu-west-3b pour haute disponibilit√© (99.99%)
- **Zero-Trust ?** ‚Üí "Never trust, always verify" - pas de confiance implicite m√™me √† l'int√©rieur du VPC
- **Production depuis quand ?** ‚Üí D√©ploiement initial en d√©cembre 2025, stabilis√© en janvier 2026

**üí° CONSEIL PR√âSENTATEUR :**
Insister sur "9 couches **ind√©pendantes**" - c'est le message cl√© qui reviendra tout au long de la pr√©sentation.

---

## SLIDE 2 - Structure de la Pr√©sentation

**üí¨ DISCOURS ORAL :**

"Maintenant, laissez-moi vous expliquer comment cette pr√©sentation est structur√©e. J'ai fait un choix d√©lib√©r√© : cette pr√©sentation suit **exactement** la structure du document technique A2A_SECURITY_ARCHITECTURE.md. Pourquoi ? Parce que je veux que vous puissiez facilement faire le lien entre ce que je vous pr√©sente aujourd'hui et la documentation d√©taill√©e que vous pourrez consulter apr√®s.

Donc regardez ce tableau : chaque section de cette pr√©sentation correspond **√† la lettre** √† une section du document. Section 2 de la pr√©sentation = Section 1 du document architecture. Section 3 = Section 2. Et ainsi de suite.

Nous allons couvrir 11 sections en 60 minutes, ce qui nous donne entre 2 et 8 minutes par section selon la complexit√©. J'ai pr√©vu 15 minutes suppl√©mentaires pour les questions √† la fin, mais n'h√©sitez pas √† m'interrompre si quelque chose n'est pas clair.

Les sections les plus longues sont Authentication & Authorization, et Protocol Security - parce que c'est l√† o√π il se passe le plus de choses int√©ressantes c√¥t√© s√©curit√©. Les sections les plus courtes comme Data Security et Threat Model sont plus des vues d'ensemble que je d√©taille moins, mais tout est dans le document pour approfondir."

**üîß REMARQUES TECHNIQUES :**
- Document source : 2,577 lignes, 11 sections techniques, version 5.1
- Derni√®re mise √† jour : 15 janvier 2026
- Aussi disponible : A2A_ATTACK_SCENARIOS_DETAILED.md (1,625 lignes, 18 sc√©narios d√©taill√©s)

**üí° CONSEIL PR√âSENTATEUR :**
Avoir le document A2A_SECURITY_ARCHITECTURE.md ouvert sur un second √©cran pour r√©f√©rence rapide en cas de questions d√©taill√©es.

---

## SLIDE 3 - Architecture Diagram

**üí¨ DISCOURS ORAL :**

"Alors, voici l'architecture compl√®te telle qu'elle est d√©ploy√©e en production. Ce diagramme correspond exactement √† celui de la Section 1.1 du document. Laissez-moi vous guider de haut en bas.

**En haut, vous avez Internet** - c'est le monde ext√©rieur, les utilisateurs, les syst√®mes clients. Ils communiquent en HTTPS avec TLS 1.2 minimum. C'est important, on n'accepte pas de TLS 1.0 ou 1.1 qui sont obsol√®tes.

**Premi√®re ligne de d√©fense : l'ALB**, l'Application Load Balancer. C'est le **seul** composant qui a une IP publique. Tout le reste est dans des subnets priv√©s. L'ALB fait la terminaison TLS, et ensuite il route le trafic vers l'orchestrateur en HTTP. Pourquoi HTTP et pas HTTPS √† l'int√©rieur ? Parce qu'on est dans un VPC isol√©, et on a d'autres m√©canismes de s√©curit√© - on en reparlera dans la section Network Security.

**L'Orchestrator sur le port 8001**, c'est le chef d'orchestre. Il re√ßoit les requ√™tes, les authentifie, les autorise, et les distribue aux agents sp√©cialis√©s. Il communique avec eux via le protocole A2A - c'est un protocole JSON-RPC 2.0 s√©curis√© par JWT.

**Les trois agents m√©tier** : Extractor (8002), Validator (8003), et Archivist (8004). Chacun a une responsabilit√© unique selon le principe de s√©paration des responsabilit√©s. L'Extractor extrait le contenu des documents, le Validator v√©rifie la conformit√© m√©tier, et l'Archivist g√®re le stockage long terme.

**Le MCP Server sur le port 8000** - c'est une nouveaut√© de la version 5.0. MCP signifie Model Context Protocol. C'est un gateway qui centralise **tous** les acc√®s aux ressources AWS. Avant, chaque agent avait ses propres credentials AWS. Maintenant, il n'y a que le MCP Server qui a acc√®s √† RDS et S3. C'est un √©norme gain en s√©curit√©, on va le d√©tailler dans la Section 4.

**En bas, les ressources** : RDS Aurora pour les m√©tadonn√©es des documents, S3 pour les fichiers eux-m√™mes, et Keycloak pour l'authentification centralis√©e OAuth2.

Point important : **regardez les fl√®ches**. Le flux est unidirectionnel de haut en bas. Les agents ne peuvent pas initier de connexions vers l'ALB. C'est une architecture en 'push' control√©."

**üîß REMARQUES TECHNIQUES D√âTAILL√âES :**

**ALB Configuration :**
- Listener 80 ‚Üí redirect to 443
- Listener 443 ‚Üí forward to Target Group (Orchestrator:8001)
- Certificate : AWS Certificate Manager (ACM), auto-renewal
- Security Policy : ELBSecurityPolicy-TLS-1-2-2017-01 (min TLS 1.2)
- Access Logs : S3 bucket ca-a2a-alb-logs, retention 90 jours

**Service Discovery (AWS Cloud Map) :**
- Namespace : ca-a2a.local (DNS priv√©)
- Services :
  - orchestrator.ca-a2a.local:8001
  - extractor.ca-a2a.local:8002
  - validator.ca-a2a.local:8003
  - archivist.ca-a2a.local:8004
  - keycloak.ca-a2a.local:8080
  - mcp-server.ca-a2a.local:8000
- TTL : 60 secondes (cache DNS)
- Health check : HTTP GET /health toutes les 30s

**RDS Aurora Details :**
- Engine : PostgreSQL 15.8 compatible
- Instance class : db.t4g.medium (2 vCPU, 4GB RAM)
- Storage : 20GB initial, autoscaling jusqu'√† 100GB
- Multi-AZ : Writer instance (AZ-a), Reader instance (AZ-b)
- Backup : automated daily snapshots, retention 7 jours
- Encryption : AES-256 at rest via AWS KMS

**Keycloak RDS Details :**
- Engine : PostgreSQL 15.8 (standalone, pas Aurora)
- Instance class : db.t4g.medium
- Storage : 20GB
- Single-AZ pour l'instant (migration Multi-AZ pr√©vue v5.2)
- Backup : automated daily

**üí° CONSEIL PR√âSENTATEUR :**
Pointer physiquement sur le diagramme en parlant. Insister visuellement sur "Seul l'ALB est public, tout le reste est priv√©".

---

## SLIDE 4 - Component Inventory

**üí¨ DISCOURS ORAL :**

"Maintenant, regardons le tableau d'inventaire complet des composants. Ce tableau vient directement de la Section 1.2 du document.

**Les agents ECS Fargate** - nous avons 4 agents m√©tier, et remarquez qu'ils tournent tous en **2 instances**. Pourquoi 2 ? Pour la haute disponibilit√©. Si une instance tombe, l'autre prend le relais imm√©diatement. Ils sont r√©partis sur deux zones de disponibilit√© diff√©rentes - eu-west-3a et eu-west-3b. Donc m√™me si un data center AWS complet tombe, le syst√®me continue de fonctionner.

**Ports d√©di√©s** - chaque agent a son propre port. Ce n'est pas juste pour l'organisation, c'est aussi pour la s√©curit√©. Avec les Security Groups AWS, on peut dire 'l'orchestrator peut appeler l'extractor sur le port 8002, mais pas l'archivist directement'. C'est du micro-segmentation au niveau r√©seau. Si un agent est compromis, il ne peut pas atteindre les autres arbitrairement.

**Keycloak** - une seule instance pour l'instant, mais c'est pr√©vu de passer √† 2 pour la haute disponibilit√© en version 5.2. C'est notre OAuth2/OIDC provider. Tous les tokens JWT sont √©mis par Keycloak. Rien n'est hardcod√©.

**MCP Server** - initialement une seule instance en v5.0, maintenant 2 instances en v5.1. C'est le gateway pour S3 et RDS. On l'a introduit en version 5.0 et √ßa a √©t√© un game changer. Avant, on avait 4 agents √ó 10 connexions = 40 connexions PostgreSQL simultan√©es. Maintenant, le MCP Server mutualise avec un pool de 10 connexions max. On a divis√© la charge sur RDS par 4.

**L'ALB** - c'est un service g√©r√© AWS, donc multi-AZ par d√©faut. Il √©coute sur les ports 80 et 443. Le port 80 redirige automatiquement vers 443, donc en pratique c'est du HTTPS only. Pas de HTTP en clair.

**Les bases de donn√©es** - deux RDS : RDS Aurora pour les documents, et un RDS PostgreSQL standard pour Keycloak. Pourquoi deux bases s√©par√©es ? Pour l'isolation des donn√©es. Si Keycloak a un probl√®me - disons un bug qui corrompt des donn√©es - √ßa n'impacte pas les m√©tadonn√©es des documents. Et vice-versa. C'est aussi pour les backups ind√©pendants."

**üîß REMARQUES TECHNIQUES D√âTAILL√âES :**

**ECS Fargate Task Specs :**
- **Orchestrator** : 1 vCPU, 2GB RAM (plus gourmand car routage)
- **Extractor** : 0.5 vCPU, 1GB RAM (PDF parsing l√©ger)
- **Validator** : 0.5 vCPU, 1GB RAM (r√®gles m√©tier en m√©moire)
- **Archivist** : 0.5 vCPU, 1GB RAM (I/O vers S3/RDS)
- **Keycloak** : 1 vCPU, 2GB RAM (Java application)
- **MCP Server** : 0.5 vCPU, 1GB RAM (gateway HTTP l√©ger)

**ALB Health Checks :**
- Endpoint : GET /health
- Interval : 30 secondes
- Timeout : 5 secondes
- Healthy threshold : 2 successful checks
- Unhealthy threshold : 3 failed checks
- Response attendue : HTTP 200 avec body `{"status":"healthy"}`

**Auto-Scaling (pr√©vu v5.2) :**
- Target Tracking policy : CPU > 70% pendant 3 minutes ‚Üí scale out
- Min instances : 2 (current)
- Max instances : 10 (planned)
- Cool-down : 5 minutes

**RDS Monitoring :**
- Enhanced Monitoring activ√© (1 seconde granularity)
- Performance Insights activ√© (7 jours retention)
- CloudWatch Alarms :
  - CPU > 80% ‚Üí alert
  - Connections > 90% max ‚Üí alert
  - Read/Write latency > 100ms ‚Üí warn

**üí° CONSEIL PR√âSENTATEUR :**
Mentionner le trade-off : "2 instances = co√ªt x2, mais disponibilit√© 99.99% vs 99.9% pour une seule instance". C'est un choix business assum√©.

---

## SLIDE 5 - 9 Security Layers Diagram

**üí¨ DISCOURS ORAL :**

"Nous arrivons maintenant au c≈ìur de la pr√©sentation : les 9 couches de s√©curit√©. Ce diagramme vient de la Section 2.1 du document. Et je veux vraiment insister sur un point : ces couches sont **ind√©pendantes**.

Qu'est-ce que √ßa veut dire concr√®tement ? √áa veut dire que si un attaquant arrive √† bypasser la couche 3 - disons qu'il a vol√© un JWT valide d'un utilisateur l√©gitime - il doit encore passer les couches 4, 5, 6, 7, 8 et 9. C'est √ßa, le defense-in-depth : multiplier les barri√®res ind√©pendantes.

Laissez-moi vous d√©tailler chaque couche :

**Couche 1 : Network Isolation** - C'est le VPC, les Security Groups, les NACLs. C'est le niveau le plus bas, le niveau r√©seau. Si vous n'√™tes pas sur le bon r√©seau IP, vous ne pouvez m√™me pas √©tablir une connexion TCP. M√™me pas un SYN/ACK.

**Couche 2 : Identity & Access** - C'est Keycloak. Vous devez prouver qui vous √™tes avant d'obtenir un token. OAuth2/OIDC standard. Client credentials flow pour les services, authorization code flow pour les humains.

**Couche 3 : Authentication** - OK, vous avez un JWT, mais est-il vraiment valide ? On v√©rifie la signature RS256 avec la cl√© publique de Keycloak r√©cup√©r√©e via JWKS. Si la signature ne matche pas - m√™me d'un seul bit - vous √™tes rejet√© imm√©diatement. Pas de deuxi√®me chance.

**Couche 4 : Authorization** - Votre token est valide, mais avez-vous le **droit** de faire cette action sp√©cifique ? C'est le RBAC - Role-Based Access Control. Un utilisateur avec le r√¥le 'viewer' ne peut pas appeler la m√©thode 'delete_document'. Period. M√™me s'il a un JWT parfaitement valide.

**Couche 5 : Resource Access Control** - **Nouvelle couche introduite en v5.0.** M√™me si vous √™tes autoris√© par RBAC, vous ne pouvez pas acc√©der directement √† RDS ou S3. Vous devez passer obligatoirement par le MCP Server. C'est un gateway qui applique ses propres r√®gles, ses propres circuit breakers, ses propres rate limits. C'est comme un deuxi√®me checkpoint ind√©pendant.

**Couche 6 : Message Integrity** - On calcule un hash SHA-256 du body JSON de la requ√™te et on le lie cryptographiquement au JWT. Si quelqu'un intercepte la requ√™te en transit et modifie ne serait-ce qu'un caract√®re dans le body, le hash ne matche plus, et on rejette. √áa prot√®ge contre les attaques man-in-the-middle m√™me √† l'int√©rieur du VPC.

**Couche 7 : Input Validation** - **Nouvelle en v5.1.** Double validation avec JSON Schema ET Pydantic. JSON Schema pour les r√®gles standard (types, patterns, longueurs), Pydantic pour les r√®gles Python type-safe avec des validateurs custom. Avant d'ex√©cuter une seule ligne de code m√©tier, on valide que tous les param√®tres respectent le sch√©ma. En production, on bloque environ 400 tentatives d'injection par jour gr√¢ce √† cette couche.

**Couche 8 : Replay Protection** - Chaque JWT a un identifiant unique - le 'jti' (JWT ID). On le track dans un cache en m√©moire. Si on voit le m√™me jti deux fois, m√™me avec un JWT parfaitement valide, c'est une attaque par rejeu. Quelqu'un a intercept√© une requ√™te l√©gitime et essaie de la rejouer. On bloque et on log un incident de s√©curit√©.

**Couche 9 : Rate Limiting** - Dernier filet de s√©curit√©. Maximum 300 requ√™tes par minute par principal - c'est-√†-dire par utilisateur ou par service. Si vous d√©passez, vous recevez un HTTP 429 - Too Many Requests. Pourquoi 300 ? Parce qu'en usage normal l√©gitime, personne ne d√©passe 100 requ√™tes par minute. On a mis une marge confortable. Mais un attaquant qui essaie de flooder le syst√®me ? Il est throttled imm√©diatement.

Remarquez les deux √©toiles rouges : les couches 5 et 7 sont nouvelles. La couche 5 est apparue en version 5.0 avec l'introduction du MCP Server. La couche 7 en version 5.1 avec JSON Schema et Pydantic. On am√©liore continuellement l'architecture."

**üîß REMARQUES TECHNIQUES D√âTAILL√âES :**

**Performance Impact par Couche :**
- L1 (Network) : ~0ms (filtrage mat√©riel AWS)
- L2 (Keycloak) : ~0ms (token d√©j√† obtenu)
- L3 (JWT verify) : ~10ms cold (JWKS fetch), ~1ms warm (cache)
- L4 (RBAC) : ~1ms (table lookup in-memory)
- L5 (MCP) : ~25ms (HTTP roundtrip + connection pool)
- L6 (Body hash) : ~1ms (SHA-256 compute)
- L7 (Validation) : ~5ms (JSON Schema + Pydantic)
- L8 (Replay check) : ~1ms (dict lookup in-memory)
- L9 (Rate limit) : ~1ms (counter increment)
- **Total : ~45-50ms overhead de s√©curit√©**

**Trade-off accept√© :** 50ms de latence pour 9 couches de protection ind√©pendantes. En production, latence P50 = 180ms, P99 = 450ms. Le surco√ªt s√©curit√© repr√©sente 25-30% de la latence totale.

**Ind√©pendance des Couches - Exemple Concret :**
Imaginez un attaquant qui a :
- ‚úÖ Bypass√© L1 (il est dans le VPC - agent compromis)
- ‚úÖ Bypass√© L2-L3 (il a vol√© un JWT valide)
- ‚úÖ Bypass√© L4 (le JWT a le bon r√¥le)

Il est **toujours bloqu√©** par :
- ‚ùå L5 : MCP Server applique ses propres ACLs
- ‚ùå L6 : S'il modifie la requ√™te, hash mismatch
- ‚ùå L7 : S'il envoie des param√®tres malform√©s, validation √©choue
- ‚ùå L8 : S'il rejoue la m√™me requ√™te, jti d√©tect√©
- ‚ùå L9 : S'il flood, rate limit d√©clench√©

**√âvolution Historique :**
- v1.0-2.0 : 4 couches (L1, L4, L8, L9) - HMAC + static tokens
- v3.0 : 6 couches - introduction JWT natif (L2-L3)
- v4.0 : 7 couches - migration Keycloak (renforcement L2-L3), ajout L6
- v5.0 : 8 couches - ajout MCP Server (L5)
- v5.1 : 9 couches - ajout JSON Schema/Pydantic (L7)

**üí° CONSEIL PR√âSENTATEUR :**
Montrer physiquement avec les doigts : "Un attaquant doit bypass 1, puis 2, puis 3, puis 4... c'est exponentiel". L'analogie des portes successives fonctionne bien.

---

## SLIDE 6 - Layer Responsibilities Table

**üí¨ DISCOURS ORAL :**

"Maintenant, d√©taillons ce que fait chaque couche et surtout **quelle menace sp√©cifique** elle mitige. Parce que c'est bien beau d'avoir 9 couches, mais il faut que chacune ait un objectif pr√©cis et mesurable.

**Layer 1 - Network Isolation** avec VPC, Security Groups, NACLs. Elle prot√®ge contre les attaques r√©seau classiques et les DDoS au niveau transport (couche 3-4 OSI). Si quelqu'un essaie de scanner vos ports depuis Internet, il ne verra m√™me pas les agents - ils sont dans des subnets priv√©s sans IP publique. M√™me les scans Nmap √©chouent.

**Layer 2 - Identity & Access** avec Keycloak centralis√©. Elle force l'authentification OAuth2/OIDC. Plus de hardcoded passwords dans le code, plus de tokens statiques en base de donn√©es, plus de `Authorization: Basic` en dur. Tout passe par Keycloak avec rotation automatique. Menace mitig√©e : unauthorized access, credential theft.

**Layer 3 - Authentication** avec JWT RS256 asym√©trique. On v√©rifie cryptographiquement que le token vient bien de Keycloak. Menace : impersonation et forged tokens. Si quelqu'un essaie de cr√©er un faux JWT - m√™me en connaissant la structure - la signature ne matchera jamais sans la cl√© priv√©e de Keycloak. Et cette cl√© ne sort jamais de Keycloak.

**Layer 4 - Authorization** avec RBAC fin-grained. OK, vous √™tes authentifi√©, mais qu'avez-vous le droit de faire exactement ? Un 'viewer' ne peut pas delete. Un 'extractor' ne peut pas acc√©der directement √† l'archivist - il doit passer par l'orchestrator. Menace : privilege escalation horizontale et verticale.

**Layer 5 - MCP Server** - c'est ma couche pr√©f√©r√©e personnellement. Elle centralise **tous** les acc√®s √† S3 et RDS au niveau infrastructure. Avant la v5.0, chaque agent avait ses propres IAM credentials AWS. Maintenant, z√©ro agent n'a acc√®s direct aux ressources. Si un agent est compl√®tement compromis - disons RCE - l'attaquant ne peut pas dump la base de donn√©es directement. Il doit passer par l'API du MCP qui applique ses propres r√®gles, logs tout, et peut √™tre circuit-break√© si comportement anormal. Menace mitig√©e : direct AWS access, lateral movement, credential sprawl. On est pass√© de 4 IAM task roles √† 1 seul. C'est 75% de r√©duction de la surface d'attaque IAM.

**Layer 6 - Message Integrity** avec JWT body hash cryptographique. On calcule un SHA-256 du body de la requ√™te normalis√© (whitespace removed), et on le stocke comme claim dans le JWT. Si quelqu'un intercepte la requ√™te et modifie le body - m√™me pour changer un seul param√®tre - le hash recalcul√© ne matchera plus le hash sign√© dans le JWT. Menace : Man-in-the-middle, request tampering, m√™me √† l'int√©rieur du VPC priv√©.

**Layer 7 - JSON Schema + Pydantic**. Double validation obligatoire des inputs avec des technologies diff√©rentes. JSON Schema pour les r√®gles d√©claratives standard (RFC, pas de code custom), Pydantic pour les r√®gles Python type-safe avec validateurs custom m√©tier. En production r√©elle, on bloque environ 400 tentatives d'injection par jour gr√¢ce √† cette couche - principalement path traversal avec `../`, SQL injection attempts, et XSS. Menace : injection attacks (SQL, NoSQL, Command, Path Traversal), DoS par malformed input (billion laughs, zip bombs).

**Layer 8 - Replay Protection** avec le jti tracking en cache. Chaque JWT contient un claim 'jti' (JWT ID) unique g√©n√©r√© par Keycloak - c'est un UUID v4. On le met dans un cache Python dict (future: Redis) avec TTL = expiration du JWT (max 5 minutes). Si on voit le m√™me jti deux fois pendant ce TTL, c'est suspect. Quelqu'un a captur√© une requ√™te valide (par exemple via log leak) et essaie de la rejouer. On bloque imm√©diatement et on d√©clenche une alerte de s√©curit√©. Menace : replay attacks, session hijacking.

**Layer 9 - Rate Limiting** applicatif par principal. 300 requ√™tes par minute par utilisateur ou service identifi√© via le JWT subject. Algorithme sliding window (future: token bucket). Si vous d√©passez, vous recevez un 429 et vous √™tes bloqu√© pendant 1 minute (cooldown). Pourquoi 300 ? Parce qu'en usage normal, personne ne d√©passe 100 req/min. On a mesur√© le P99 des utilisateurs l√©gitimes sur 30 jours : 85 req/min. On a mis 3.5x de marge. Mais un attaquant qui essaie de flooder avec un compte compromis ? Il est stopp√© net apr√®s 300 requ√™tes. Menace : resource exhaustion, DoS applicatif, credential stuffing attacks.

Et regardez bien la colonne 'Technology' - chaque couche utilise une technologie diff√©rente. On ne met pas tous les ≈ìufs dans le m√™me panier. Si AWS Security Groups ont un bug (√ßa arrive, CVE-2019-XXXX), on a encore 8 autres couches avec des impl√©mentations totalement diff√©rentes. C'est de la diversit√© d√©fensive."

**üîß REMARQUES TECHNIQUES ULTRA-D√âTAILL√âES :**

**L1 - Network Isolation - Performance :**
- Security Groups : stateful firewall, filtrage kernel Linux eBPF
- Latence : < 1 microseconde (hardware offload sur AWS Nitro)
- Throughput : 25 Gbps (instance Fargate limit)

**L2 - Keycloak - Scalabilit√© :**
- Single instance actuelle : ~1000 tokens/seconde
- Cluster planned v5.2 : 2 instances + load balancer = ~2000 tokens/sec
- Database bottleneck : PostgreSQL Keycloak, max 100 connections

**L3 - JWT Verification - Cache Strategy :**
- JWKS (JSON Web Key Set) fetched from Keycloak `/realms/ca-a2a/protocol/openid-connect/certs`
- Cache TTL : 1 heure (Keycloak key rotation < 24h)
- Cache miss penalty : ~50ms (HTTPS call + JSON parse)
- Cache hit : ~1ms (RSA verify from cached key)

**L4 - RBAC - Mapping Table :**
```python
ROLE_MAPPING = {
    "admin": ["*"],  # All methods
    "orchestrator": ["extract_document", "validate_document", "archive_document"],
    "document-processor": ["process_document", "list_pending", "check_status"],
    "viewer": ["list_documents", "get_document", "check_status"]
}
```
- Lookup : O(1) dict access
- Enforcement point : `@require_role()` decorator on each method

**L5 - MCP Server - Connection Pooling :**
- PostgreSQL pool : min 2, max 10 connections (asyncpg)
- S3 client : 1 shared boto3 session, connection pooling automatique
- Circuit breaker : 5 failures dans 10 secondes ‚Üí open pendant 30 secondes
- Retry policy : exponential backoff 100ms, 200ms, 400ms (max 3 retries)

**L6 - Body Hash - Algorithm :**
```python
def compute_body_hash(body: dict) -> str:
    canonical = json.dumps(body, sort_keys=True, separators=(',', ':'))
    return hashlib.sha256(canonical.encode('utf-8')).hexdigest()
```
- Canonicalization : sorted keys, no whitespace
- Hash : SHA-256 (64 hex chars)
- Storage : JWT claim `body_hash`

**L7 - Input Validation - Stats Production :**
- Total requests/day : ~50,000
- Validation failures/day : ~400 (0.8%)
- Top failure reasons :
  - Path traversal (`..` in s3_key) : 45%
  - Missing required fields : 30%
  - Type mismatch (string instead of int) : 15%
  - Length exceeded (> 1024 chars) : 10%

**L8 - Replay Protection - Implementation :**
```python
jti_cache = {}  # Future: Redis with TTL
def check_replay(jti: str, exp: int) -> bool:
    if jti in jti_cache:
        return True  # Replay detected
    jti_cache[jti] = time.time()
    # Cleanup expired entries every 5 minutes (background task)
```

**L9 - Rate Limiting - Algorithm :**
```python
# Sliding window log
rate_limits = {}  # principal -> [(timestamp, count)]
def check_rate_limit(principal: str) -> bool:
    now = time.time()
    window = now - 60  # 1 minute
    # Remove old entries
    rate_limits[principal] = [(ts, c) for ts, c in rate_limits.get(principal, []) if ts > window]
    # Count total
    total = sum(c for ts, c in rate_limits[principal])
    if total >= 300:
        return False  # Rate limit exceeded
    rate_limits[principal].append((now, 1))
    return True
```

**üí° ANALOGIE EFFICACE :**
"C'est comme un a√©roport : vous avez le contr√¥le des passeports (L2-L3), la fouille des bagages (L7), la douane (L4), le scan corporel (L6), et le nombre de vols max par jour (L9). Si quelqu'un bypass un contr√¥le, il y en a 8 autres."

---

## SLIDE 7 - Complete Request Security Flow

**üí¨ DISCOURS ORAL :**

"Maintenant, voyons concr√®tement ce qui se passe quand une requ√™te traverse le syst√®me. Ce tableau vient de la Section 2.3 du document et montre les checkpoints de chaque couche.

Imaginez qu'un utilisateur envoie une requ√™te pour traiter un document. Voici le parcours de s√©curit√© complet :

**Checkpoint L1 - R√©seau :** Le paquet r√©seau arrive. L'AWS Security Group v√©rifie : est-ce que l'IP source est autoris√©e ? Est-ce que le port de destination (443) est ouvert ? Si non, le paquet est drop silencieusement au niveau kernel. Pas de response, pas de trace. Connection refused. L'attaquant ne sait m√™me pas qu'il y a un serveur derri√®re.

**Checkpoint L2 - Identit√© :** Le request HTTP arrive √† l'orchestrator. On v√©rifie : y a-t-il un header `Authorization: Bearer` ? Si non, on retourne imm√©diatement un HTTP 401 Unauthorized avec un JSON-RPC error `-32010`. Pas de JWT = pas d'acc√®s. Period.

**Checkpoint L3 - Authentication :** Le JWT est pr√©sent. On le parse, on v√©rifie la signature RS256 avec la cl√© publique Keycloak (via JWKS). Si la signature est invalide - ou si le token est expir√© (claim `exp` < now) - on retourne un 401 avec "Invalid Token". La signature cryptographique garantit que le token vient bien de Keycloak et n'a pas √©t√© modifi√©.

**Checkpoint L4 - Authorization :** Le JWT est valide. Maintenant on extrait les r√¥les depuis `realm_access.roles` dans le JWT payload. On les map vers nos principals internes. On v√©rifie : est-ce que ce principal a le droit d'appeler cette m√©thode sp√©cifique (par exemple `process_document`) ? Si non, HTTP 403 Forbidden. Vous √™tes authentifi√©, mais pas autoris√© pour cette action.

**Checkpoint L5 - Ressources MCP :** L'agent veut acc√©der √† S3 ou RDS. On v√©rifie que le MCP Server est op√©rationnel (circuit breaker ferm√©). Si le MCP est down ou en circuit ouvert, on retourne un 503 Service Unavailable. On ne laisse pas l'agent attendre un timeout de 30 secondes.

**Checkpoint L6 - Int√©grit√© :** On recalcule le hash SHA-256 du body JSON de la requ√™te. On le compare au claim `body_hash` dans le JWT. Si √ßa ne match pas, √ßa veut dire que quelqu'un a modifi√© la requ√™te apr√®s que le JWT ait √©t√© sign√©. On retourne un 403 Forbidden avec "Tampering detected". C'est un incident de s√©curit√© qu'on log imm√©diatement.

**Checkpoint L7 - Validation :** On valide les param√®tres contre le JSON Schema, puis contre le mod√®le Pydantic. Est-ce que `s3_key` contient `..` (path traversal) ? Est-ce que `priority` est dans ["low", "normal", "high"] ? Est-ce que les longueurs respectent les limites ? Si non, HTTP 400 Bad Request avec "Invalid params" et le d√©tail exact de ce qui est invalide.

**Checkpoint L8 - Replay :** On extrait le claim `jti` du JWT. On v√©rifie s'il existe dans notre cache. Si oui, c'est une attaque par rejeu - quelqu'un a r√©utilis√© un token qui a d√©j√† servi. On retourne un 403 Forbidden avec "Replay detected". On log l'incident avec le subject du JWT (quel utilisateur/service est compromis).

**Checkpoint L9 - Rate :** On v√©rifie le compteur de requ√™tes pour ce principal dans la derni√®re minute. Si > 300, on retourne un 429 Too Many Requests avec un header `Retry-After: 60` qui dit au client de r√©essayer dans 1 minute.

**Si tous les checkpoints passent**, la requ√™te est finalement ex√©cut√©e par le code m√©tier. On retourne un HTTP 200 avec le r√©sultat.

Remarquez que chaque checkpoint a un code d'erreur HTTP et JSON-RPC sp√©cifique. √áa permet au client de savoir **exactement** quelle couche a rejet√© la requ√™te et pourquoi. C'est crucial pour le debugging et l'incident response."

**üîß REMARQUES TECHNIQUES - Flow D√©taill√© avec Timing :**

**Exemple Concret - Requ√™te L√©gitime :**
```
T+0ms    : ALB re√ßoit HTTPS request
T+2ms    : L1 Security Group check ‚Üí PASS (IP autoris√©e)
T+3ms    : Routage vers Orchestrator :8001
T+4ms    : L2 JWT pr√©sent ? ‚Üí PASS (header pr√©sent)
T+5ms    : L3 JWT signature valid ? ‚Üí PASS (RS256 verified via JWKS cache)
T+6ms    : L4 RBAC check ‚Üí PASS (role "document-processor" can call "process_document")
T+7ms    : L6 Body hash match ? ‚Üí PASS (SHA-256 match)
T+12ms   : L7 JSON Schema validation ‚Üí PASS (all fields valid)
T+13ms   : L8 Replay check ‚Üí PASS (jti not in cache, add to cache)
T+14ms   : L9 Rate limit check ‚Üí PASS (102 requests this minute, < 300)
T+15ms   : Forward to Extractor via A2A protocol
T+40ms   : Extractor calls MCP Server for S3 access
T+41ms   : L5 MCP circuit breaker ‚Üí PASS (closed, operational)
T+65ms   : MCP fetches from S3
T+150ms  : Total processing (extraction + validation + archival)
T+180ms  : Response HTTP 200 avec result
```

**Exemple - Requ√™te Rejet√©e Layer 7 (Path Traversal) :**
```
T+0ms    : Request arrives avec {"s3_key": "../../../etc/passwd"}
T+1-13ms : L1-L6 passent (JWT valide, autoris√©, etc.)
T+14ms   : L7 JSON Schema validation d√©tecte pattern `\\.\\.`
T+14ms   : REJECT avec HTTP 400
Response:
{
  "jsonrpc": "2.0",
  "id": "req-12345",
  "error": {
    "code": -32602,
    "message": "Invalid params",
    "data": {
      "field": "s3_key",
      "reason": "Path traversal not allowed",
      "pattern_violation": ".."
    }
  }
}
```

**Exemple - Requ√™te Rejet√©e Layer 8 (Replay) :**
```
T+0ms    : Request arrives avec JWT d√©j√† vu (jti="abc-123")
T+1-12ms : L1-L7 passent (tout semble l√©gitime)
T+13ms   : L8 Replay check trouve jti="abc-123" dans cache
T+13ms   : REJECT avec HTTP 403
Logged incident:
{
  "level": "WARN",
  "event_type": "replay_detected",
  "jti": "abc-123",
  "subject": "user-uuid-5678",
  "ip": "10.0.10.42",
  "timestamp": "2026-01-15T14:23:11Z"
}
```

**Codes d'Erreur par Couche :**
- L1 : Connection refused (pas de response HTTP)
- L2 : 401 + JSON-RPC -32010 "Unauthorized"
- L3 : 401 + JSON-RPC -32010 "Invalid Token"
- L4 : 403 + JSON-RPC -32011 "Forbidden"
- L5 : 503 + JSON-RPC -32603 "Service Unavailable"
- L6 : 403 + JSON-RPC custom "Tampering Detected"
- L7 : 400 + JSON-RPC -32602 "Invalid params"
- L8 : 403 + JSON-RPC -32013 "Replay detected"
- L9 : 429 + JSON-RPC -32012 "Rate limit exceeded"

**üí° CONSEIL INCIDENT RESPONSE :**
"Quand vous recevez une alerte, le code d'erreur vous dit exactement quelle couche a d√©tect√© le probl√®me. 403 + code -32013 = replay attack ‚Üí check les logs du subject pour voir si le compte est compromis."

---

## SLIDES 8-34 - Notes Abr√©g√©es

Pour les slides restants (8 √† 34), je fournis des **bullet points cl√©s** plut√¥t que du discours complet, car le pattern est √©tabli :

### SLIDE 8 - Keycloak Flow

**üí¨ POINTS CL√âS :**
- Flux OAuth2 Client Credentials
- Keycloak √©met JWT avec RS256
- Refresh token pour rotation automatique
- TTL 5 minutes pour limiter blast radius si vol

**üîß TECHNIQUE :**
- Endpoint : `POST http://keycloak.ca-a2a.local:8080/realms/ca-a2a/protocol/openid-connect/token`
- Body : `grant_type=client_credentials&client_id=...&client_secret=...`
- Response : `{"access_token": "eyJ...", "expires_in": 300, "refresh_token": "..."}`

### SLIDE 9 - JWT Structure

**üí¨ POINTS CL√âS :**
- Header : alg=RS256 (asym√©trique), kid pour key rotation
- Payload : exp (5 min), jti (unique), realm_access.roles
- Pas de donn√©es sensibles dans payload (c'est base64, pas chiffr√©)

**üîß TECHNIQUE :**
- Taille typique : ~800 bytes
- Overhead par requ√™te : +800 bytes vs. session cookie
- Trade-off : stateless (scalable) vs. taille

### SLIDE 10 - RBAC Mapping

**üí¨ POINTS CL√âS :**
- 5 r√¥les : admin (god mode), lambda (S3 events), orchestrator, document-processor, viewer
- Mapping statique dans code (pas de DB lookup)
- Principe du moindre privil√®ge

**üîß TECHNIQUE :**
- Implementation : decorator `@require_role("document-processor")`
- Enforcement point : avant chaque method call
- Audit : tous les access logs contiennent le role

### SLIDE 11 - Token Revocation

**üí¨ POINTS CL√âS :**
- Architecture hybride : cache in-memory (fast) + PostgreSQL (persistent)
- 99% hits dans cache (~1Œºs)
- Auto-cleanup toutes les 5 minutes

**üîß TECHNIQUE :**
- Table : `revoked_tokens(jti PRIMARY KEY, revoked_at, revoked_by, reason, expires_at)`
- Admin API : `POST /admin/revoke-token {jti}`
- Stats : ~10 r√©vocations/jour en moyenne

### SLIDE 12-14 - MCP Server

**üí¨ POINTS CL√âS :**
- Avant : 4 agents √ó IAM credentials = sprawl
- Maintenant : 1 seul gateway MCP
- -88% connexions DB, -75% IAM roles

**üîß TECHNIQUE :**
- Connection pool PostgreSQL : max 10 (asyncpg)
- Circuit breaker : 5 failures ‚Üí open 30s
- Overhead : +25ms latency, acceptable trade-off

### SLIDE 15-17 - Network Security

**üí¨ POINTS CL√âS :**
- VPC 10.0.0.0/16, subnets publics (ALB) vs priv√©s (agents)
- Security Groups : micro-segmentation port-by-port
- VPC Endpoints : trafic AWS reste priv√© (pas d'internet)

**üîß TECHNIQUE :**
- NAT Gateway pour outbound (yum updates, etc.)
- Service Discovery : ca-a2a.local (DNS priv√©)
- Pas de 0.0.0.0/0 inbound sauf ALB

### SLIDE 18-20 - Data Security

**üí¨ POINTS CL√âS :**
- Encryption at rest : AES-256 partout (RDS, S3, EBS, Secrets Manager)
- Encryption in transit : TLS 1.2+ vers ext√©rieur, HTTP dans VPC (√† am√©liorer)
- Zero secrets hardcod√©s

**üîß TECHNIQUE :**
- AWS KMS pour key management
- Secrets Manager avec rotation automatique (planned)
- RDS storage encryption obligatoire

### SLIDE 21-26 - Protocol Security (A2A)

**üí¨ POINTS CL√âS :**
- JSON-RPC 2.0 standard
- JSON Schema validation (d√©claratif)
- Pydantic models (type-safe Python)
- 6 couches de validation avant code m√©tier

**üîß TECHNIQUE :**
- Path traversal blocked : regex `not: {"pattern": "\\.\\."}`
- Error codes : -32700 √† -32603 (standard), -32010 √† -32014 (custom s√©curit√©)
- Stats : ~400 injections bloqu√©es/jour

### SLIDE 27-29 - Monitoring & Audit

**üí¨ POINTS CL√âS :**
- CloudWatch Logs structur√©s JSON
- Correlation IDs end-to-end
- M√©triques custom : AuthFailures, RateLimitViolations
- Retention 7 jours

**üîß TECHNIQUE :**
- Log groups : `/ecs/ca-a2a-{agent-name}`
- CloudWatch Insights queries disponibles dans doc
- Alarms : CPU > 80%, latency > 500ms

### SLIDE 30-31 - Threat Model

**üí¨ POINTS CL√âS :**
- STRIDE analysis complet
- 18 sc√©narios d'attaque document√©s
- Chaque menace mapped vers layers de d√©fense

**üîß TECHNIQUE :**
- Document d√©taill√© : A2A_ATTACK_SCENARIOS_DETAILED.md
- Mermaid diagrams pour chaque sc√©nario
- Code vuln√©rable ‚Üí s√©curis√© pour chaque cas

### SLIDE 32-34 - Conclusion

**üí¨ MESSAGES CL√âS :**
1. Defense-in-depth avec 9 couches ind√©pendantes
2. Keycloak centralis√© = zero-trust architecture
3. MCP Server = game changer (v5.0)
4. JSON Schema + Pydantic = validation robuste (v5.1)
5. Observabilit√© avec correlation IDs

**üîß NEXT STEPS :**
- v5.2 : Keycloak HA (2 instances)
- v5.3 : TLS inter-agent
- v6.0 : Redis pour jti cache et rate limiting

---

## Questions Anticip√©es - R√©ponses D√©taill√©es

### Q1 : "Pourquoi HTTP entre agents dans le VPC ?"

**üí¨ R√âPONSE :**
"Excellente question. C'est un choix d√©lib√©r√© bas√© sur plusieurs facteurs. Premi√®rement, on est dans un VPC compl√®tement isol√© avec Security Groups stricts. Deuxi√®mement, on a d√©j√† une signature JWT qui lie cryptographiquement l'identit√© et le body de la requ√™te - c'est une forme de channel binding. Troisi√®mement, le overhead TLS (~5-10ms par requ√™te √ó 4 agents) s'accumule.

Ceci dit, vous avez raison de soulever le point. Dans une approche defense-in-depth pure, on devrait activer TLS inter-agent. C'est pr√©vu en v5.3. On va utiliser AWS Certificate Manager Private CA pour √©mettre des certificats internes avec rotation automatique. L'overhead sera compens√© par TLS 1.3 avec session resumption."

**üîß D√âTAIL TECHNIQUE :**
- TLS 1.3 handshake : ~2 RTT ‚Üí ~10ms in-VPC
- Session resumption : 0-RTT ‚Üí ~0ms (apr√®s first connection)
- Certificate rotation : automated via ACM Private CA
- Cost : ~$400/mois (CA maintenance + certificate issuance)

### Q2 : "Performance impact du MCP Server ?"

**üí¨ R√âPONSE :**
"Le MCP Server ajoute environ 25 millisecondes de latence par acc√®s S3/RDS. C'est mesurable et non n√©gligeable - 25ms sur une requ√™te totale de 180ms P50, √ßa repr√©sente 14% d'overhead.

Mais regardons les b√©n√©fices :
- On a r√©duit les connexions PostgreSQL de 80 (4 agents √ó 20 connexions) √† 10 (pool mutualis√©). √áa a r√©duit la charge CPU sur RDS de 40%.
- On a centralis√© l'audit : 100% des acc√®s S3/RDS sont logg√©s au m√™me endroit. Avant, on devait corr√©ler 4 log streams diff√©rents.
- On a r√©duit de 75% le nombre de IAM roles √† auditer et √† maintenir.

Le trade-off est clairement positif. Et avec le caching qu'on va ajouter en v5.2 (Redis cache pour metadata fr√©quentes), on va r√©duire cet overhead √† ~10ms pour les cache hits."

**üîß METRICS PRODUCTION :**
- Avant MCP :
  - RDS connections : 40-80 simultan√©es
  - RDS CPU : 65% average
  - Latency P50 : 160ms
- Apr√®s MCP :
  - RDS connections : 8-12 simultan√©es
  - RDS CPU : 35% average (-46%)
  - Latency P50 : 180ms (+12.5%)
  - **Trade-off accept√©**

### Q3 : "Tokens r√©voqu√©s √† grande √©chelle ?"

**üí¨ R√âPONSE :**
"On a test√© avec 10,000 tokens r√©voqu√©s simultan√©ment. L'architecture hybride cache + PostgreSQL tient tr√®s bien.

Le secret, c'est le TTL court des JWT : 5 minutes maximum. √áa veut dire qu'un token r√©voqu√© 'expire naturellement' apr√®s 5 minutes max m√™me sans r√©vocation explicite. Donc on ne garde les JTI en cache que pendant leur TTL.

Avec 10K tokens/jour, TTL moyen 2.5 minutes, on a ~150 JTI en cache √† tout instant. C'est ~5KB de RAM. Trivial.

Le cleanup automatique tourne toutes les 5 minutes et supprime les entr√©es expir√©es. En prod, on a ~30 r√©vocations actives en moyenne."

**üîß ALGORITHM :**
```python
def cleanup_expired_jti():
    now = time.time()
    jti_cache = {jti: exp for jti, exp in jti_cache.items() if exp > now}
    # Runs every 5 minutes via background task
```

### Q4 : "Plan disaster recovery ?"

**üí¨ R√âPONSE :**
"On a plusieurs niveaux :

**RDS Aurora** : snapshots automatiques quotidiens, retention 7 jours. Backup incr√©mental toutes les 5 minutes dans S3. En cas de disaster, on peut restaurer √† n'importe quel point dans le temps avec RPO (Recovery Point Objective) de 5 minutes.

**RDS Keycloak** : m√™me chose, snapshots quotidiens, retention 7 jours.

**S3** : versioning activ√©, lifecycle policy vers Glacier apr√®s 90 jours. Pas de suppression d√©finitive avant 1 an.

**ECS Tasks** : stateless, donc disaster recovery = relancer les tasks. Temps de recovery ~3 minutes (cold start ECS).

**RTO** (Recovery Time Objective) global : 15 minutes pour restaurer le syst√®me complet."

**üîß PROC√âDURE DR :**
1. Identify issue (automatic CloudWatch alarms)
2. Restore RDS from snapshot (~10 min)
3. Restart ECS services (automatic via health checks)
4. Verify Keycloak operational
5. Resume traffic (ALB targets healthy)

### Q5 : "Conformit√© RGPD ?"

**üí¨ R√âPONSE :**
"On a trois piliers RGPD :

**Chiffrement** : AES-256 at rest partout, TLS 1.2+ in transit. √áa couvre le 'mesures techniques appropri√©es'.

**Audit trail** : Tous les acc√®s logg√©s avec correlation IDs. On peut tracer qui a acc√©d√© √† quelles donn√©es et quand. √áa couvre le 'droit d'information'.

**Acc√®s contr√¥l√©** : RBAC strict, principe du moindre privil√®ge. Un operator ne peut pas acc√©der aux donn√©es m√©tier, seulement aux m√©triques.

**Ce qu'il manque** : Le droit √† l'oubli (right to be forgotten). Pour l'instant, on supprime manuellement via SQL. On va impl√©menter un endpoint `DELETE /gdpr/forget/{user_id}` en v5.3 qui anonymise toutes les donn√©es li√©es √† un utilisateur."

**üîß GDPR CHECKLIST :**
- ‚úÖ Encryption at rest/transit
- ‚úÖ Audit logs (who, when, what)
- ‚úÖ Access control (RBAC)
- ‚úÖ Data minimization (only necessary fields stored)
- ‚ö†Ô∏è Right to be forgotten (manual for now, API planned)
- ‚ö†Ô∏è Data portability (export API planned)
- ‚úÖ Data retention (7 jours logs, 90 jours S3)

---

## Conseils G√©n√©raux de Pr√©sentation

### Timing

- Rester dans les 60 minutes (slide 2-32)
- Si vous prenez du retard, √©courter les sections 6 (Data Security) et 10 (Security Operations)
- Si vous avez de l'avance, approfondir la section 4 (MCP Server) - c'est la plus int√©ressante

### Interaction

- Encourager les questions pendant (pas seulement √† la fin)
- Si question complexe : "Excellente question, je vais y r√©pondre en d√©tail √† la fin pour ne pas d√©border"
- Pointer physiquement sur les diagrammes pour maintenir l'attention

### Emphase

- **Moments cl√©s √† marteler** :
  1. "9 couches **ind√©pendantes**" (r√©p√©ter 3x minimum)
  2. "Defense-in-depth : pas de single point of failure"
  3. "MCP Server : -88% connexions DB, -75% IAM roles"
  4. "~400 injections bloqu√©es/jour par Layer 7"

### Gestion des Questions Difficiles

**Q: "Pourquoi pas mTLS partout ?"**
R: "Co√ªt vs. b√©n√©fice. On a d√©j√† JWT signature + body hash. mTLS ajouterait ~15ms. C'est pr√©vu en v5.3 maintenant qu'on a stabilis√© le reste."

**Q: "Pourquoi ECS et pas Kubernetes ?"**
R: "Fargate = serverless, moins de surface d'attaque (pas de nodes √† patcher). K8s = plus flexible mais plus complexe. Pour nos besoins, Fargate suffit."

**Q: "Single Keycloak = SPOF ?"**
R: "Oui, reconnu. Migration vers cluster HA 2 instances en v5.2. Pour l'instant, RTO Keycloak ~5 minutes (red√©marrage automatique ECS)."

---

**FIN DES NOTES DE DISCOURS ORAL**

**Dur√©e couverte : 60 minutes de pr√©sentation + 15 minutes Q&A**

**Document √† utiliser c√¥te-√†-c√¥te avec : PRESENTATION_ARCHITECTURE_SECURITE.md**

